{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(val):\n",
    "    return REV_CLASS_MAP[val]\n",
    "\n",
    "\n",
    "def calculate_winner(move1, move2):\n",
    "    if move1 == move2:\n",
    "        return \"Tie\"\n",
    "\n",
    "    if move1 == \"rock\":\n",
    "        if move2 == \"scissors\":\n",
    "            return \"You\"\n",
    "        if move2 == \"paper\":\n",
    "            return \"Finn\"\n",
    "\n",
    "    if move1 == \"paper\":\n",
    "        if move2 == \"rock\":\n",
    "            return \"You\"\n",
    "        if move2 == \"scissors\":\n",
    "            return \"Finn\"\n",
    "\n",
    "    if move1 == \"scissors\":\n",
    "        if move2 == \"paper\":\n",
    "            return \"You\"\n",
    "        if move2 == \"rock\":\n",
    "            return \"Finn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finn_nr():\n",
    "    finn = cv2.imread('images/Finn_neural.png', cv2.IMREAD_UNCHANGED)\n",
    "    finn = cv2.resize(finn, (400, 400))\n",
    "    finn_alpha = finn[:, :, 3]  # Extract the alpha channel\n",
    "\n",
    "    frame_roi = frame[100:500, 0:400]  # Select the region of interest in the frame\n",
    "\n",
    "    # Resize the alpha channel to match the size of the ROI\n",
    "    finn_alpha_resized = cv2.resize(finn_alpha, (frame_roi.shape[1], frame_roi.shape[0]))\n",
    "\n",
    "    # Create a three-channel alpha mask\n",
    "    alpha_mask = np.zeros_like(frame_roi)\n",
    "    for c in range(3):\n",
    "        alpha_mask[:, :, c] = finn_alpha_resized\n",
    "\n",
    "    # Apply the alpha mask to the ROI\n",
    "    frame_roi_with_finn = cv2.bitwise_and(frame_roi, cv2.bitwise_not(alpha_mask))\n",
    "    finn_with_background = cv2.bitwise_and(finn[:, :, :3], alpha_mask)\n",
    "    combined = cv2.add(frame_roi_with_finn, finn_with_background)\n",
    "\n",
    "    # Update the frame with the combined image\n",
    "    frame[100:500, 0:400] = combined\n",
    "\n",
    "def finn_sad():\n",
    "    finn = cv2.imread('images/Finn_sad.png', cv2.IMREAD_UNCHANGED)\n",
    "    finn = cv2.resize(finn, (400, 400))\n",
    "    finn_alpha = finn[:, :, 3]  # Extract the alpha channel\n",
    "\n",
    "    frame_roi = frame[100:500, 0:400]  # Select the region of interest in the frame\n",
    "\n",
    "    # Resize the alpha channel to match the size of the ROI\n",
    "    finn_alpha_resized = cv2.resize(finn_alpha, (frame_roi.shape[1], frame_roi.shape[0]))\n",
    "\n",
    "    # Create a three-channel alpha mask\n",
    "    alpha_mask = np.zeros_like(frame_roi)\n",
    "    for c in range(3):\n",
    "        alpha_mask[:, :, c] = finn_alpha_resized\n",
    "\n",
    "    # Apply the alpha mask to the ROI\n",
    "    frame_roi_with_finn = cv2.bitwise_and(frame_roi, cv2.bitwise_not(alpha_mask))\n",
    "    finn_with_background = cv2.bitwise_and(finn[:, :, :3], alpha_mask)\n",
    "    combined = cv2.add(frame_roi_with_finn, finn_with_background)\n",
    "\n",
    "    # Update the frame with the combined image\n",
    "    frame[100:500, 0:400] = combined\n",
    "\n",
    "def finn_chanhr():\n",
    "    finn = cv2.imread('images/Finn_chanhr.png', cv2.IMREAD_UNCHANGED)\n",
    "    finn = cv2.resize(finn, (400, 400))\n",
    "    finn_alpha = finn[:, :, 3]  # Extract the alpha channel\n",
    "\n",
    "    frame_roi = frame[100:500, 0:400]  # Select the region of interest in the frame\n",
    "\n",
    "    # Resize the alpha channel to match the size of the ROI\n",
    "    finn_alpha_resized = cv2.resize(finn_alpha, (frame_roi.shape[1], frame_roi.shape[0]))\n",
    "\n",
    "    # Create a three-channel alpha mask\n",
    "    alpha_mask = np.zeros_like(frame_roi)\n",
    "    for c in range(3):\n",
    "        alpha_mask[:, :, c] = finn_alpha_resized\n",
    "\n",
    "    # Apply the alpha mask to the ROI\n",
    "    frame_roi_with_finn = cv2.bitwise_and(frame_roi, cv2.bitwise_not(alpha_mask))\n",
    "    finn_with_background = cv2.bitwise_and(finn[:, :, :3], alpha_mask)\n",
    "    combined = cv2.add(frame_roi_with_finn, finn_with_background)\n",
    "\n",
    "    # Update the frame with the combined image\n",
    "    frame[100:500, 0:400] = combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 23:40:47.466 python[24226:464547] _TIPropertyValueIsValid called with 4 on nil context!\n",
      "2023-06-08 23:40:47.466 python[24226:464547] imkxpc_getApplicationProperty:reply: called with incorrect property value 4, bailing.\n",
      "2023-06-08 23:40:47.466 python[24226:464547] Text input context does not respond to _valueForTIProperty:\n",
      "2023-06-09 08:33:09.262 python[24226:464547] _TIPropertyValueIsValid called with 4 on nil context!\n",
      "2023-06-09 08:33:09.262 python[24226:464547] imkxpc_getApplicationProperty:reply: called with incorrect property value 4, bailing.\n",
      "2023-06-09 08:33:09.263 python[24226:464547] Text input context does not respond to _valueForTIProperty:\n",
      "2023-06-09 08:33:09.265 python[24226:464547] IMKClient Stall detected, *please Report* your user scenario attaching a spindump (or sysdiagnose) that captures the problem - (imkxpc_presentFunctionRowItemTextInputViewWithEndpoint:reply:) block performed very slowly (31930.03 secs).\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model and label mapping\n",
    "label_name_mapping = {'1': 'paper', '2': 'rock', '3': 'scissors', '4': 'nothing'}\n",
    "\n",
    "# Initialize VideoCapture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize mediapipe hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "prev_move = None\n",
    "computer_move_name = \"\" \n",
    "user_move_name = \"\" \n",
    "winner = \"\"\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # rectangle for user to play\n",
    "    cv2.rectangle(frame, (250, 100), (650, 500), (255, 255, 255), 2)\n",
    "    # rectangle for computer to play\n",
    "    cv2.rectangle(frame, (800, 100), (1200, 500), (255, 255, 255), 2)\n",
    "\n",
    "    # convert the frame to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Check if hand is within the specified rectangle\n",
    "            hand_rect_w = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * image.shape[1]\n",
    "            hand_rect_h = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * image.shape[0]\n",
    "\n",
    "            if hand_rect_w > image.shape[1] - 500 and hand_rect_h < 500:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Extract hand landmarks coordinates\n",
    "                count = 1\n",
    "                coordinates = []\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    if count == 1:\n",
    "                        x0 = landmark.x\n",
    "                        y0 = landmark.y\n",
    "                        coordinates.extend([0, 0])\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        x = landmark.x\n",
    "                        y = landmark.y\n",
    "                        x = round(x - x0, 5)\n",
    "                        y = round(y - y0, 5)\n",
    "                        coordinates.extend([x, y])\n",
    "\n",
    "                # Perform the prediction\n",
    "                input_data = np.array([coordinates])\n",
    "                predicted_probs = model.predict(input_data)[0]\n",
    "                predicted_label = np.argmax(predicted_probs) + 1\n",
    "                move_code = str(predicted_label)\n",
    "                user_move_name = label_name_mapping[move_code]\n",
    "\n",
    "                # predict the winner (human vs computer)\n",
    "                if prev_move != user_move_name:\n",
    "                    if user_move_name != \"nothing\":\n",
    "                        computer_move_name = choice(['rock', 'paper', 'scissors'])\n",
    "                        winner = calculate_winner(user_move_name, computer_move_name)\n",
    "                    else:\n",
    "                        computer_move_name = \"nothing\"\n",
    "                        winner = \"Waiting...\"\n",
    "                prev_move = user_move_name\n",
    "                if computer_move_name != \"none\":\n",
    "\n",
    "                    icon = cv2.imread(\n",
    "                        \"images/{}.png\".format(computer_move_name))\n",
    "                    icon = cv2.resize(icon, (400, 400))\n",
    "                    frame[100:500, 250:650] = icon\n",
    "\n",
    "                    if winner == 'You': finn_sad()\n",
    "                    elif winner =='Finn': finn_chanhr()\n",
    "                    else: finn_nr()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Display the information\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, \"Finn's move: \" + computer_move_name,\n",
    "                            (250, 50), font, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"Your move: \" + user_move_name,\n",
    "                            (800, 50), font, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"Winner: \" + winner,\n",
    "                            (550, 600), font, 2, (0, 0, 255), 4, cv2.LINE_AA)\n",
    "\n",
    "                \n",
    "    cv2.imshow(\"Play game with Finn\", frame)\n",
    "\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
